{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Hotel Ratings on Tripadvisor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework we will practice web scraping. Let's get some basic information for each hotel in Boston."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On each hotel page, scrape the Traverler ratings. **(10 pts)**\n",
    "\n",
    "![Information to be scraped](traveler_ratings.png)\n",
    "\n",
    "Save the data in \"traverler_ratings.csv\" in the following format:\n",
    "\n",
    "hotel_name, rating, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "import requests\n",
    "import codecs\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "base_url = \"http://www.tripadvisor.com\"\n",
    "user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.76 Safari/537.36\"\n",
    "df_names = pd.DataFrame(columns=['name'])\n",
    "df_names_final = pd.DataFrame(columns=['name'])\n",
    "df_rnames = pd.DataFrame(columns=['rname'])\n",
    "df_rnames_final = pd.DataFrame(columns=['rname'])\n",
    "df_ratings = pd.DataFrame(columns=['rating'])\n",
    "df_ratings_final = pd.DataFrame(columns=['rating'])\n",
    "\n",
    "def get_tourism_page(city):\n",
    "    \"\"\"\n",
    "        Return json containing the URL\n",
    "        of the tourism city page\n",
    "    \"\"\"\n",
    "\n",
    "    # EXAMPLE: http://www.tripadvisor.com/Boston\n",
    "    url = base_url+ \"/\"+ city \n",
    "    \n",
    "    # Given the url, request the HTML page\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    html = response.text.encode('utf-8')\n",
    "\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "    li = soup.find(\"link\", {\"hreflang\": \"en\"})\n",
    "    #return li['href']\n",
    "    \n",
    "    return 'https://www.tripadvisor.com/Tourism-g60745-Boston_Massachusetts-Vacations.html'\n",
    "    \n",
    "def get_city_page(tourism_url):\n",
    "    \"\"\"\n",
    "        Get the URL of the hotels of the city\n",
    "        using the URL returned by the function\n",
    "        get_tourism_page()\n",
    "        \"\"\"\n",
    "\n",
    "    url = tourism_url\n",
    "    # Given the url, request the HTML page\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    html = response.text.encode('utf-8')\n",
    "\n",
    "    # Use BeautifulSoup to extract the url for the list of hotels in\n",
    "    # the city and state we are interested in.\n",
    "    # For exampel in this case we need to\n",
    "    #<li class=\"hotels twoLines\">\n",
    "    #<a href=\"/Hotels-g60745-Boston_Massachusetts-Hotels.html\" data-trk=\"hotels_nav\"\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "    li = soup.find(\"li\", {\"class\": \"hotels twoLines\"})\n",
    "    city_url = li.find('a', href = True)\n",
    "\n",
    "    return city_url['href']\n",
    "\n",
    "def get_hotellist_page(city_url):\n",
    "    \"\"\" Get the hotel list page given the url returned by\n",
    "        get_city_page(). Return the html after saving\n",
    "        it to the datadir\n",
    "    \"\"\"\n",
    "\n",
    "    url = base_url + city_url\n",
    "    # Sleep 2 sec before starting a new http request\n",
    "    time.sleep(2)\n",
    "    # Request page\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    html = response.text.encode('utf-8')\n",
    "    return html\n",
    "\n",
    "def hotel_traveller_rating(url):\n",
    "    html = get_hotellist_page(url)\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "    hotel_rating = soup.find('div',{'class':'col rating '})\n",
    "    row_name = soup.select('div.row_label')\n",
    "    \n",
    "    rname = []\n",
    "    for i in row_name:\n",
    "        n = i.find(text=True)\n",
    "        rname.append(n) \n",
    "    row_rating = hotel_rating.select('li')\n",
    "    \n",
    "    rating=[]\n",
    "    names = []\n",
    "    for i in row_rating:\n",
    "        name = soup.find('div',{'class':'warLocName'})\n",
    "        name= name.find(text=True)\n",
    "        names.append(name)\n",
    "        count = i.find('span',{'class':''}).find(text=True)\n",
    "        rating.append(count)\n",
    "        #print(j.find(text=True))\n",
    "    df_names['name']=names\n",
    "    df_rnames['rname']=rname\n",
    "    df_ratings['rating']=rating\n",
    "    global df_names_final\n",
    "    global df_rnames_final\n",
    "    global df_ratings_final\n",
    "    df_names_final = df_names_final.append(df_names,ignore_index=True)\n",
    "    df_rnames_final = df_rnames_final.append(df_rnames,ignore_index=True)\n",
    "    df_ratings_final = df_ratings_final.append(df_ratings,ignore_index=True)\n",
    "\n",
    "def parse_hotellist_page(html):\n",
    "    \"\"\" Parse the html pages returned by get_hotellist_page().\n",
    "        Return the next url page to scrape (a city can have\n",
    "        more than one page of hotels) if there is, else exit\n",
    "        the script.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "    # Extract hotel name, star rating and number of reviews\n",
    "    hotel_boxes = soup.select('div.listing.easyClear.p13n_imperfect')\n",
    "    \n",
    "    # hotel_boxes = soup.find_all('div', {'class' :'listing easyClear  p13n_imperfect '})\n",
    "    for hotel_box in hotel_boxes:\n",
    "#         name = hotel_box.find('div', {'class' :'listing_title'}).find(text=True)\n",
    "#         print(\"HOTEL NAME: {}\".format(name))\n",
    "        hotel_link = hotel_box.find('a', {'class' : 'property_title'})\n",
    "        hotel_traveller_rating(hotel_link['href'])\n",
    "        \n",
    "    # Get next URL page if exists, else exit\n",
    "    div = soup.find(\"div\", {\"class\" : \"unified pagination standard_pagination\"})\n",
    "    # check if last page\n",
    "    if div.find('span', {'class' : 'nav next ui_button disabled'}):\n",
    "        print(\"We reached last page\") \n",
    "    # If it is not las page there must be the Next URL\n",
    "    hrefs = div.findAll('a', href= True)\n",
    "    for href in hrefs:\n",
    "        if href.find(text = True) == 'Next':\n",
    "            print(\"Next url is :\",href['href'])\n",
    "            return href['href']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next url is : /Hotels-g60745-oa30-Boston_Massachusetts-Hotels.html#ACCOM_OVERVIEW\n",
      "Next url is : /Hotels-g60745-oa60-Boston_Massachusetts-Hotels.html#ACCOM_OVERVIEW\n",
      "We reached last page\n"
     ]
    }
   ],
   "source": [
    "# Obtain the url of the toursim page \n",
    "tourism_url = get_tourism_page('Boston')\n",
    "    \n",
    "#Get URL to obtaint the list of hotels in a specific city\n",
    "city_url = get_city_page(tourism_url)\n",
    "\n",
    "c=0\n",
    "while(True):\n",
    "    c +=1\n",
    "    if city_url == None:\n",
    "        break\n",
    "    html = get_hotellist_page(city_url)\n",
    "    city_url = parse_hotellist_page(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2b01997d1968>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hotel_name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_names_final\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rating'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_rnames_final\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rname'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'count'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_ratings_final\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rating'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_final\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df_final = pd.DataFrame()\n",
    "df_final['hotel_name'] = df_names_final['name']\n",
    "df_final['rating'] = df_rnames_final['rname'] \n",
    "df_final['count'] = df_ratings_final['rating']\n",
    "print(df_final)\n",
    "df_final.to_csv('traveller_ratings.csv',index=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, scrape all the reviews of each hotel for the star ratings of the following attributes: Value, Location, Sleep Quality, Rooms, Cleanliness, Service. Note that some reviews may not have attribute ratings and some may only have some of the attributes. **(25 pts)**\n",
    "\n",
    "![Information to be scraped](attribute_ratings.png)\n",
    "\n",
    "Save the data in \"attribute_ratings.csv\" in the following format:\n",
    "\n",
    "hotel_name, review_id, attribute, star_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "import requests\n",
    "import codecs\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "base_url = \"http://www.tripadvisor.com\"\n",
    "user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.76 Safari/537.36\"\n",
    "\n",
    "hname = []\n",
    "rid = []\n",
    "attr = []\n",
    "svalue = []\n",
    "\n",
    "def get_tourism_page(city):\n",
    "    \"\"\"\n",
    "        Return json containing the URL\n",
    "        of the tourism city page\n",
    "    \"\"\"\n",
    "\n",
    "    # EXAMPLE: http://www.tripadvisor.com/Boston\n",
    "    url = base_url+ \"/\"+ city \n",
    "    \n",
    "    # Given the url, request the HTML page\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    html = response.text.encode('utf-8')\n",
    "\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "    li = soup.find(\"link\", {\"hreflang\": \"en\"})\n",
    "    \n",
    "    #print(li)\n",
    "    #return li['href']\n",
    "    return 'https://www.tripadvisor.com/Tourism-g60745-Boston_Massachusetts-Vacations.html'\n",
    "\n",
    "def get_city_page(tourism_url):\n",
    "    \"\"\"\n",
    "        Get the URL of the hotels of the city\n",
    "        using the URL returned by the function\n",
    "        get_tourism_page()\n",
    "        \"\"\"\n",
    "\n",
    "    url = tourism_url\n",
    "    # Given the url, request the HTML page\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    html = response.text.encode('utf-8')\n",
    "\n",
    "    # Use BeautifulSoup to extract the url for the list of hotels in\n",
    "    # the city and state we are interested in.\n",
    "    # For exampel in this case we need to\n",
    "    #<li class=\"hotels twoLines\">\n",
    "    #<a href=\"/Hotels-g60745-Boston_Massachusetts-Hotels.html\" data-trk=\"hotels_nav\"\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "    li = soup.find(\"li\", {\"class\": \"hotels twoLines\"})\n",
    "    city_url = li.find('a', href = True)\n",
    "\n",
    "    return city_url['href']\n",
    "\n",
    "def get_hotellist_page(city_url):\n",
    "    \"\"\" Get the hotel list page given the url returned by\n",
    "        get_city_page(). Return the html after saving\n",
    "        it to the datadir\n",
    "    \"\"\"\n",
    "\n",
    "    url = base_url + city_url\n",
    "    # Sleep 2 sec before starting a new http request\n",
    "    time.sleep(2)\n",
    "    # Request page\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    html = response.text.encode('utf-8')\n",
    "    return html\n",
    "\n",
    "def extract_reviewr(url, hotel_name,sleep):\n",
    "    html = get_hotellist_page(url)\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "    \n",
    "    review_id = soup.select('div.reviewSelector')\n",
    "    for m in review_id:\n",
    "        review_rating = m.select('div.rating-list')\n",
    "        for s in review_rating:\n",
    "            col_1 = s.find('li')\n",
    "            if col_1 == None:\n",
    "                continue\n",
    "            rating = col_1.select('img')\n",
    "            rating_name = col_1.select('div.recommend-description')\n",
    "            for i,j in zip(rating_name,rating):\n",
    "                hname.append(hotel_name)\n",
    "                rid.append(m['id'])\n",
    "                attr.append(i.find(text=True))\n",
    "                svalue.append(j['alt'][0])\n",
    "    div = soup.find('div',{'class':'unified pagination '})\n",
    "    if div.find('span',{'class':'nav next disabled'}):\n",
    "        print('Reached last page')\n",
    "    else:\n",
    "        sleep+=1\n",
    "        if sleep%50 == 0:\n",
    "            time.sleep(1)\n",
    "        button = div.find('a',{'class':'nav next rndBtn ui_button primary taLnk'})\n",
    "        extract_reviewr(button['href'], hotel_name,sleep)\n",
    "    \n",
    "def hotel_traveller_review(url):\n",
    "    html = get_hotellist_page(url)\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "    hotel_name = soup.find('h1').find(text=True)\n",
    "    hotel_reviews = soup.find('div',{'class':'innerBubble'})\n",
    "    review_link = hotel_reviews.find('a')\n",
    "    extract_reviewr(review_link['href'], hotel_name,0)\n",
    "\n",
    "    \n",
    "def parse_hotellist_page(html):\n",
    "    \"\"\" Parse the html pages returned by get_hotellist_page().\n",
    "        Return the next url page to scrape (a city can have\n",
    "        more than one page of hotels) if there is, else exit\n",
    "        the script.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "    # Extract hotel name, star rating and number of reviews\n",
    "    hotel_boxes = soup.select('div.listing.easyClear.p13n_imperfect')\n",
    "    \n",
    "    # hotel_boxes = soup.find_all('div', {'class' :'listing easyClear  p13n_imperfect '})\n",
    "    for hotel_box in hotel_boxes:\n",
    "        hotel_link = hotel_box.find('a', {'class' : 'property_title'})\n",
    "        hotel_traveller_review(hotel_link['href'])\n",
    "        \n",
    "    # Get next URL page if exists, else exit\n",
    "    div = soup.find(\"div\", {\"class\" : \"unified pagination standard_pagination\"})\n",
    "    # check if last page\n",
    "    if div.find('span', {'class' : 'nav next ui_button disabled'}):\n",
    "        print(\"We reached last page\") \n",
    "    # If it is not las page there must be the Next URL\n",
    "    hrefs = div.findAll('a', href= True)\n",
    "    for href in hrefs:\n",
    "        if href.find(text = True) == 'Next':\n",
    "            print(\"Next url is :\",href['href'])\n",
    "            return href['href']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Obtain the url of the toursim page \n",
    "city = 'Boston'\n",
    "tourism_url = get_tourism_page(city)\n",
    "    \n",
    "#Get URL to obtaint the list of hotels in a specific city\n",
    "city_url = get_city_page(tourism_url)\n",
    "\n",
    "c=0\n",
    "while(True):\n",
    "    \n",
    "    c +=1\n",
    "    if city_url == None:\n",
    "        break\n",
    "    html = get_hotellist_page(city_url)\n",
    "    city_url = parse_hotellist_page(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220717\n"
     ]
    }
   ],
   "source": [
    "final_df = pd.DataFrame()\n",
    "final_df['hotel_name'] = hname\n",
    "final_df['review_id'] = rid\n",
    "final_df['attribute'] = attr\n",
    "final_df['star_value'] = svalue\n",
    "print(len(final_df))\n",
    "final_df.to_csv('attribute_ratings.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marriott Vacation Club Pulse at Custom House, Boston\n",
      "Boston Harbor Hotel\n",
      "Seaport Boston Hotel\n",
      "Four Seasons Hotel Boston\n",
      "Lenox Hotel\n",
      "Courtyard Boston Copley Square\n",
      "InterContinental Boston\n",
      "Hotel Commonwealth\n",
      "Mandarin Oriental, Boston\n",
      "Residence Inn Boston Back Bay/Fenway\n",
      "Eliot Hotel\n",
      "XV Beacon\n",
      "Residence Inn Boston Downtown/Seaport\n",
      "Kimpton Nine Zero Hotel\n",
      "Hilton Garden Inn Boston Logan Airport\n",
      "The Verb Hotel\n",
      "The Godfrey Hotel Boston\n",
      "enVision Hotel Boston - Longwood\n",
      "The Langham, Boston\n",
      "Loews Boston Hotel\n",
      "The Boxer Boston\n",
      "Colonnade Hotel\n",
      "Residence Inn Boston Harbor on Tudor Wharf\n",
      "Fairmont Copley Plaza, Boston\n",
      "Copley Square Hotel\n",
      "W Boston\n",
      "The Bostonian Boston\n",
      "Taj Boston\n",
      "The Westin Copley Place, Boston\n",
      "Newbury Guest House\n",
      "Next url is : /Hotels-g60745-oa30-Boston_Massachusetts-Hotels.html#ACCOM_OVERVIEW\n",
      "The Ritz-Carlton, Boston\n",
      "The Envoy Hotel, Autograph Collection\n",
      "Hyatt Regency Boston Harbor\n",
      "Hyatt Regency Boston\n",
      "Kimpton Onyx Hotel\n",
      "Boston Marriott Long Wharf\n",
      "The Liberty, A Luxury Collection Hotel\n",
      "The Westin Boston Waterfront\n",
      "Revere Hotel Boston Common\n",
      "Ames Boston Hotel, Curio Collection by Hilton\n",
      "The Inn At St Botolph\n",
      "Battery Wharf Hotel, Boston Waterfront\n",
      "Renaissance Boston Waterfront Hotel\n",
      "Omni Parker House\n",
      "DoubleTree by Hilton Hotel Boston - Downtown\n",
      "Sheraton Boston Hotel\n",
      "Club Quarters Hotel in Boston\n",
      "Harborside Inn\n",
      "Charlesmark Hotel\n",
      "Boston Marriott Copley Place\n",
      "DoubleTree Suites by Hilton Boston-Cambridge\n",
      "Hotel 140\n",
      "The Inn at Longwood Medical\n",
      "Holiday Inn Express Boston\n",
      "Hilton Boston Back Bay\n",
      "Boston Park Plaza\n",
      "Embassy Suites by Hilton Boston - at Logan Airport\n",
      "Hilton Boston Downtown / Faneuil Hall\n",
      "Hilton Boston Logan Airport\n",
      "DoubleTree Club by Hilton Hotel Boston Bayside\n",
      "Next url is : /Hotels-g60745-oa60-Boston_Massachusetts-Hotels.html#ACCOM_OVERVIEW\n",
      "Element Boston Seaport\n",
      "Reached last page\n",
      "Hampton Inn & Suites Boston Crosstown Center\n",
      "Reached last page\n",
      "Chandler Inn\n",
      "Reached last page\n",
      "Wyndham Boston Beacon Hill\n",
      "Reached last page\n",
      "Copley House\n",
      "Reached last page\n",
      "Boston Hotel Buckminster\n",
      "Reached last page\n",
      "The Midtown Hotel\n",
      "Reached last page\n",
      "Aloft Boston Seaport\n",
      "Reached last page\n",
      "Holiday Inn Express Hotel & Suites Boston Garden\n",
      "Reached last page\n",
      "Courtyard Boston Downtown\n",
      "Reached last page\n",
      "Courtyard Boston Logan Airport\n",
      "Reached last page\n",
      "Courtyard Boston-South Boston\n",
      "Reached last page\n",
      "Beacon Hill Hotel and Bistro\n",
      "Reached last page\n",
      "BEST WESTERN PLUS Roundhouse Suites\n",
      "Reached last page\n",
      "Comfort Inn - Boston\n",
      "Reached last page\n",
      "Hotel Boston\n",
      "Reached last page\n",
      "Ramada Boston\n",
      "Reached last page\n",
      "Milner Hotel\n",
      "Reached last page\n",
      "The Boston Common Hotel and Conference Center\n",
      "Reached last page\n",
      "Constitution Inn\n",
      "Reached last page\n",
      "Americas Best Value Inn\n",
      "Reached last page\n",
      "Days Hotel Boston-Harvard Fenway\n",
      "Reached last page\n",
      "We reached last page\n"
     ]
    }
   ],
   "source": [
    "\"Continuing from the last hotel when jupyter notebook crashed\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "import requests\n",
    "import codecs\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "base_url = \"http://www.tripadvisor.com\"\n",
    "user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.76 Safari/537.36\"\n",
    "jump = 0\n",
    "\n",
    "def get_tourism_page():\n",
    "    return 'https://www.tripadvisor.com/Tourism-g60745-Boston_Massachusetts-Vacations.html'\n",
    "\n",
    "def get_city_page(tourism_url):\n",
    "    \"\"\"\n",
    "        Get the URL of the hotels of the city\n",
    "        using the URL returned by the function\n",
    "        get_tourism_page()\n",
    "        \"\"\"\n",
    "\n",
    "    url = tourism_url\n",
    "    # Given the url, request the HTML page\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    html = response.text.encode('utf-8')\n",
    "\n",
    "    # Use BeautifulSoup to extract the url for the list of hotels in\n",
    "    # the city and state we are interested in.\n",
    "    # For exampel in this case we need to\n",
    "    #<li class=\"hotels twoLines\">\n",
    "    #<a href=\"/Hotels-g60745-Boston_Massachusetts-Hotels.html\" data-trk=\"hotels_nav\"\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "    li = soup.find(\"li\", {\"class\": \"hotels twoLines\"})\n",
    "    city_url = li.find('a', href = True)\n",
    "\n",
    "    return city_url['href']\n",
    "\n",
    "def get_hotellist_page(city_url):\n",
    "    \"\"\" Get the hotel list page given the url returned by\n",
    "        get_city_page(). Return the html after saving\n",
    "        it to the datadir\n",
    "    \"\"\"\n",
    "\n",
    "    url = base_url + city_url\n",
    "    # Sleep 2 sec before starting a new http request\n",
    "    time.sleep(2)\n",
    "    # Request page\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    html = response.text.encode('utf-8')\n",
    "    return html\n",
    "\n",
    "\n",
    "def hotel_traveller_review(url):\n",
    "    html = get_hotellist_page(url)\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "    hotel_name = soup.find('h1').find(text=True)\n",
    "    hotel_reviews = soup.find('div',{'class':'innerBubble'})\n",
    "    review_link = hotel_reviews.find('a')\n",
    "    extract_reviewr(review_link['href'], hotel_name,0)\n",
    "\n",
    "def extract_reviewr(url, hotel_name,sleep):\n",
    "    html = get_hotellist_page(url)\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "    \n",
    "    review_id = soup.select('div.reviewSelector')\n",
    "    for m in review_id:\n",
    "        review_rating = m.select('div.rating-list')\n",
    "        for s in review_rating:\n",
    "            col_1 = s.find('li')\n",
    "            if col_1 == None:\n",
    "                continue\n",
    "            rating = col_1.select('img')\n",
    "            rating_name = col_1.select('div.recommend-description')\n",
    "            for i,j in zip(rating_name,rating):\n",
    "                with open('attribute_ratings.csv', 'a', newline='') as file:\n",
    "                    writer = csv.writer(file,quoting=csv.QUOTE_MINIMAL)\n",
    "                    writer.writerow([hotel_name,m['id'],i.find(text=True),j['alt'][0]])\n",
    "    div = soup.find('div',{'class':'unified pagination '})\n",
    "    if div.find('span',{'class':'nav next disabled'}):\n",
    "        print('Reached last page')\n",
    "    else:\n",
    "        sleep+=1\n",
    "        if sleep%50 == 0:\n",
    "            time.sleep(1)\n",
    "        button = div.find('a',{'class':'nav next rndBtn ui_button primary taLnk'})\n",
    "        extract_reviewr(button['href'], hotel_name,sleep)\n",
    "\n",
    "\n",
    "def parse_hotellist_page_from_current(html,jump):\n",
    "    \"\"\" Parse the html pages returned by get_hotellist_page().\n",
    "        Return the next url page to scrape (a city can have\n",
    "        more than one page of hotels) if there is, else exit\n",
    "        the script.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "    # Extract hotel name, star rating and number of reviews\n",
    "    hotel_boxes = soup.select('div.listing.easyClear.p13n_imperfect')\n",
    "    \n",
    "    # hotel_boxes = soup.find_all('div', {'class' :'listing easyClear  p13n_imperfect '})\n",
    "    for hotel_box in hotel_boxes:\n",
    "        current_name = hotel_box.find('div', {'class' :'listing_title'}).find(text=True)\n",
    "        print(current_name)\n",
    "        if jump == 0:\n",
    "            if current_name != last_hotel:\n",
    "                continue\n",
    "            else:\n",
    "                jump = 1\n",
    "        hotel_link = hotel_box.find('a', {'class' : 'property_title'})\n",
    "        hotel_traveller_review(hotel_link['href'])\n",
    "            \n",
    "    # Get next URL page if exists, else exit\n",
    "    div = soup.find(\"div\", {\"class\" : \"unified pagination standard_pagination\"})\n",
    "    # check if last page\n",
    "    if div.find('span', {'class' : 'nav next ui_button disabled'}):\n",
    "        print(\"We reached last page\") \n",
    "    # If it is not las page there must be the Next URL\n",
    "    hrefs = div.findAll('a', href= True)\n",
    "    for href in hrefs:\n",
    "        if href.find(text = True) == 'Next':\n",
    "            print(\"Next url is :\",href['href'])\n",
    "            return href['href']\n",
    "\n",
    "\n",
    "last_hotel = \"Element Boston Seaport\"\n",
    "tourism_url = get_tourism_page()\n",
    "city_url = get_city_page(tourism_url)\n",
    "\n",
    "while(city_url!=None):\n",
    "    html = get_hotellist_page(city_url)\n",
    "    city_url = parse_hotellist_page_from_current(html,jump)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
